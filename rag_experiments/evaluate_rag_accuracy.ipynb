{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate CVE→CWE Matching Accuracy (Hybrid RAG)\n",
        "\n",
        "Goal: evaluate how well our system predicts CWE(s) **when the CVE record already contains explicit CWE labels**.\n",
        "\n",
        "Method:\n",
        "- Use all CVEs with at least one explicit `cweId` in `containers.cna.problemTypes`.\n",
        "- Hide the label(s), predict from the CVE description.\n",
        "- Accuracy = % where the predicted CWE matches any ground-truth CWE for that CVE.\n",
        "\n",
        "We report:\n",
        "- **Top‑1 accuracy** (best prediction)\n",
        "- **Top‑k accuracy** (ground-truth appears in retrieved top‑k list)\n",
        "\n",
        "Notes:\n",
        "- Running over *all* CVEs can take a while; the notebook supports sampling / max limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /home/dnfy/Desktop/Fortiss\n",
            "CWE XML: /home/dnfy/Desktop/Fortiss/data/cwec_v4.19.xml\n",
            "CVE root: /home/dnfy/Desktop/Fortiss/data/cvelistV5-main/cves\n",
            "Exists? True True\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "CWE_XML_PATH = PROJECT_ROOT / \"data\" / \"cwec_v4.19.xml\"\n",
        "CVE_ROOT = PROJECT_ROOT / \"data\" / \"cvelistV5-main\" / \"cves\"\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"CWE XML:\", CWE_XML_PATH)\n",
        "print(\"CVE root:\", CVE_ROOT)\n",
        "print(\"Exists?\", CWE_XML_PATH.exists(), CVE_ROOT.exists())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load CWE definitions (ground truth catalog)\n",
        "\n",
        "We build:\n",
        "- `cwe_map`: `CWE-<id>` → `{name, description}`\n",
        "- `cwe_corpus`: list of dense text strings used by the retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWEs: 969\n"
          ]
        }
      ],
      "source": [
        "def parse_cwe_database(xml_path: Path):\n",
        "    cwe_map = {}\n",
        "    cwe_corpus = []\n",
        "\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    ns = {\"cwe\": root.tag.split(\"}\")[0].strip(\"{\")} if \"}\" in root.tag else {}\n",
        "    xpath = \".//cwe:Weakness\" if ns else \".//Weakness\"\n",
        "\n",
        "    for weakness in root.findall(xpath, ns):\n",
        "        wid = weakness.get(\"ID\")\n",
        "        wname = weakness.get(\"Name\")\n",
        "\n",
        "        desc_elem = weakness.find(\"cwe:Description\", ns) if ns else weakness.find(\"Description\")\n",
        "        description = (desc_elem.text or \"\").strip() if desc_elem is not None else \"\"\n",
        "        if not description:\n",
        "            description = \"No description available.\"\n",
        "\n",
        "        cwe_id = f\"CWE-{wid}\"\n",
        "        cwe_map[cwe_id] = {\"name\": wname, \"description\": description}\n",
        "\n",
        "        text = f\"{cwe_id}: {wname}. {description}\"\n",
        "        cwe_corpus.append({\"id\": cwe_id, \"name\": wname, \"description\": description, \"text\": text})\n",
        "\n",
        "    return cwe_map, cwe_corpus\n",
        "\n",
        "\n",
        "cwe_map, cwe_corpus = parse_cwe_database(CWE_XML_PATH)\n",
        "print(\"CWEs:\", len(cwe_map))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build retriever (TF‑IDF fallback + optional SBERT)\n",
        "\n",
        "- Default: TF‑IDF + cosine similarity (offline, fast, no downloads)\n",
        "- Optional: SBERT (`sentence-transformers/all-mpnet-base-v2`) if installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dnfy/Desktop/Fortiss/fortiss_env/lib64/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Batches: 100%|██████████| 31/31 [00:01<00:00, 17.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retriever backend: sbert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def _normalize_text(s: str) -> str:\n",
        "    s = (s or \"\").lower()\n",
        "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def _tokenize(s: str):\n",
        "    return [t for t in _normalize_text(s).split(\" \") if t]\n",
        "\n",
        "\n",
        "def build_tfidf_index(texts: list[str]):\n",
        "    n_docs = len(texts)\n",
        "    doc_term_counts = []\n",
        "    df = {}\n",
        "\n",
        "    for text in texts:\n",
        "        counts = {}\n",
        "        for tok in _tokenize(text):\n",
        "            counts[tok] = counts.get(tok, 0) + 1\n",
        "        doc_term_counts.append(counts)\n",
        "        for tok in counts.keys():\n",
        "            df[tok] = df.get(tok, 0) + 1\n",
        "\n",
        "    vocab = {tok: i for i, tok in enumerate(sorted(df.keys()))}\n",
        "    n_terms = len(vocab)\n",
        "\n",
        "    rows, cols, vals = [], [], []\n",
        "    for r, counts in enumerate(doc_term_counts):\n",
        "        for tok, tf in counts.items():\n",
        "            c = vocab[tok]\n",
        "            rows.append(r)\n",
        "            cols.append(c)\n",
        "            vals.append(float(tf))\n",
        "\n",
        "    tf = sp.csr_matrix((vals, (rows, cols)), shape=(n_docs, n_terms), dtype=np.float32)\n",
        "\n",
        "    idf_vec = np.empty(n_terms, dtype=np.float32)\n",
        "    for tok, c in vocab.items():\n",
        "        idf_vec[c] = math.log((1.0 + n_docs) / (1.0 + df[tok])) + 1.0\n",
        "\n",
        "    X = tf.multiply(idf_vec)\n",
        "\n",
        "    row_norm = np.sqrt(X.multiply(X).sum(axis=1)).A1\n",
        "    row_norm[row_norm == 0] = 1.0\n",
        "    X = sp.diags(1.0 / row_norm).dot(X)\n",
        "\n",
        "    return X, vocab, idf_vec\n",
        "\n",
        "\n",
        "def tfidf_query(text: str, vocab, idf_vec):\n",
        "    counts = {}\n",
        "    for tok in _tokenize(text):\n",
        "        if tok in vocab:\n",
        "            counts[tok] = counts.get(tok, 0) + 1\n",
        "\n",
        "    if not counts:\n",
        "        return sp.csr_matrix((1, len(vocab)), dtype=np.float32)\n",
        "\n",
        "    rows, cols, vals = [], [], []\n",
        "    for tok, tf in counts.items():\n",
        "        rows.append(0)\n",
        "        cols.append(vocab[tok])\n",
        "        vals.append(float(tf))\n",
        "\n",
        "    q_tf = sp.csr_matrix((vals, (rows, cols)), shape=(1, len(vocab)), dtype=np.float32)\n",
        "    q = q_tf.multiply(idf_vec)\n",
        "\n",
        "    q_norm = np.sqrt(q.multiply(q).sum(axis=1)).A1\n",
        "    q_norm[q_norm == 0] = 1.0\n",
        "    q = q.multiply(1.0 / q_norm[0])\n",
        "\n",
        "    return q\n",
        "\n",
        "\n",
        "_cwe_texts = [c[\"text\"] for c in cwe_corpus]\n",
        "X_tfidf, vocab, idf_vec = build_tfidf_index(_cwe_texts)\n",
        "\n",
        "RETRIEVER_BACKEND = \"tfidf\"\n",
        "\n",
        "\n",
        "def retrieve_topk(query_text: str, k: int = 5):\n",
        "    q = tfidf_query(query_text, vocab, idf_vec)\n",
        "    sims = (X_tfidf @ q.T).toarray().ravel()\n",
        "    top_idx = np.argsort(-sims)[:k]\n",
        "    return [(int(i), float(sims[int(i)])) for i in top_idx]\n",
        "\n",
        "\n",
        "# Optional SBERT backend\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    _sbert = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "    _cwe_emb = _sbert.encode(_cwe_texts, normalize_embeddings=True, show_progress_bar=True)\n",
        "    RETRIEVER_BACKEND = \"sbert\"\n",
        "\n",
        "    def retrieve_topk(query_text: str, k: int = 5):\n",
        "        q = _sbert.encode([query_text], normalize_embeddings=True)[0]\n",
        "        sims = _cwe_emb @ q\n",
        "        top_idx = np.argsort(-sims)[:k]\n",
        "        return [(int(i), float(sims[int(i)])) for i in top_idx]\n",
        "\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"Retriever backend:\", RETRIEVER_BACKEND)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load CVEs with explicit CWE labels\n",
        "\n",
        "We iterate all `CVE-*.json` under the local CVE tree and keep only those with:\n",
        "- at least one explicit `cweId` that looks like `CWE-<digits>`\n",
        "- a non-empty English description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iterator ready.\n"
          ]
        }
      ],
      "source": [
        "CWE_ID_RE = re.compile(r\"^CWE-\\d+$\")\n",
        "\n",
        "\n",
        "def extract_explicit_cwes(cve_data: dict) -> list[str]:\n",
        "    cwe_ids = []\n",
        "    problem_types = cve_data.get(\"containers\", {}).get(\"cna\", {}).get(\"problemTypes\", [])\n",
        "    for pt in problem_types:\n",
        "        for desc in pt.get(\"descriptions\", []):\n",
        "            cwe_id = desc.get(\"cweId\")\n",
        "            if isinstance(cwe_id, str) and CWE_ID_RE.match(cwe_id):\n",
        "                cwe_ids.append(cwe_id)\n",
        "    return sorted(set(cwe_ids))\n",
        "\n",
        "\n",
        "def extract_cve_description(cve_data: dict) -> str:\n",
        "    descs = cve_data.get(\"containers\", {}).get(\"cna\", {}).get(\"descriptions\", [])\n",
        "    for d in descs:\n",
        "        if d.get(\"lang\") == \"en\" and d.get(\"value\"):\n",
        "            return str(d.get(\"value\")).strip()\n",
        "    for d in descs:\n",
        "        if d.get(\"value\"):\n",
        "            return str(d.get(\"value\")).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def iter_labeled_cves(cve_root: Path):\n",
        "    \"\"\"Yield dicts: {cve_id, description, true_cwes} for CVEs with explicit CWE labels.\"\"\"\n",
        "    for p in cve_root.rglob(\"CVE-*.json\"):\n",
        "        try:\n",
        "            data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        cve_id = data.get(\"cveMetadata\", {}).get(\"cveId\") or p.stem\n",
        "        cve_id = str(cve_id)\n",
        "\n",
        "        true_cwes = extract_explicit_cwes(data)\n",
        "        if not true_cwes:\n",
        "            continue\n",
        "\n",
        "        desc = extract_cve_description(data)\n",
        "        if not desc:\n",
        "            continue\n",
        "\n",
        "        yield {\"cve_id\": cve_id, \"description\": desc, \"true_cwes\": true_cwes}\n",
        "\n",
        "\n",
        "# Quick count (can take a bit; you can skip this cell if slow)\n",
        "# n = sum(1 for _ in iter_labeled_cves(CVE_ROOT))\n",
        "# print(\"Labeled CVEs:\", n)\n",
        "print(\"Iterator ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation\n",
        "\n",
        "We compute:\n",
        "- **top‑1**: whether the highest‑ranked retrieved CWE matches any ground truth\n",
        "- **top‑k**: whether any of the retrieved top‑k CWEs matches any ground truth\n",
        "\n",
        "Controls:\n",
        "- `MAX_RECORDS`: set `None` to evaluate all labeled CVEs (can be slow)\n",
        "- `SHUFFLE`: randomize order before taking `MAX_RECORDS`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total labeled CVEs found: 101404\n",
            "Evaluating: 100 records\n",
            "[20/100] top1=0.250 top5=0.600 hyde=20/20 (fail=0) llm_top1=0.550 (used=20, none=0, fail=0) elapsed=68.6s\n",
            "[40/100] top1=0.125 top5=0.450 hyde=40/40 (fail=0) llm_top1=0.350 (used=40, none=0, fail=0) elapsed=136.4s\n",
            "[60/100] top1=0.167 top5=0.433 hyde=60/60 (fail=0) llm_top1=0.350 (used=60, none=0, fail=0) elapsed=201.9s\n",
            "[80/100] top1=0.212 top5=0.450 hyde=80/80 (fail=0) llm_top1=0.375 (used=80, none=0, fail=0) elapsed=270.9s\n",
            "[100/100] top1=0.210 top5=0.440 hyde=100/100 (fail=0) llm_top1=0.380 (used=100, none=0, fail=0) elapsed=335.5s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'n': 100,\n",
              " 'top1_acc': 0.21,\n",
              " 'top5_acc': 0.44,\n",
              " 'elapsed_s': 335.46481823921204,\n",
              " 'backend': 'sbert',\n",
              " 'mistakes_sample': [{'cve_id': 'CVE-2025-30151',\n",
              "   'true': ['CWE-20'],\n",
              "   'pred_topk': ['CWE-307', 'CWE-645', 'CWE-549', 'CWE-648', 'CWE-303'],\n",
              "   'desc': \"Shopware is an open commerce platform. It's possible to pass long passwords that leads to Denial Of Service via forms in Storefront forms or Store-API. This vulnerability is fixed in 6.6.10.3 or 6.5.8.17. For older versions of 6.4, corresponding security measures are also available via a plugin. For\"},\n",
              "  {'cve_id': 'CVE-2022-30238',\n",
              "   'true': ['CWE-287'],\n",
              "   'pred_topk': ['CWE-556', 'CWE-520', 'CWE-307', 'CWE-645', 'CWE-671'],\n",
              "   'desc': 'A CWE-287: Improper Authentication vulnerability exists that could allow an attacker to take over the admin account when an attacker hijacks a session. Affected Products: Wiser Smart, EER21000 & EER21001 (V4.5 and prior)'},\n",
              "  {'cve_id': 'CVE-2022-39085',\n",
              "   'true': ['CWE-77'],\n",
              "   'pred_topk': ['CWE-266', 'CWE-520', 'CWE-114', 'CWE-269', 'CWE-648'],\n",
              "   'desc': 'In network service, there is a missing permission check. This could lead to local escalation of privilege with System execution privileges needed.'},\n",
              "  {'cve_id': 'CVE-2022-1087',\n",
              "   'true': ['CWE-79'],\n",
              "   'pred_topk': ['CWE-692', 'CWE-85', 'CWE-83', 'CWE-81', 'CWE-80'],\n",
              "   'desc': 'A vulnerability, which was classified as problematic, has been found in htmly 5.3 whis affects the component Edit Profile Module. The manipulation of the field Title with script tags leads to persistent cross site scripting. The attack may be initiated remotely and requires an authentication. A simp'},\n",
              "  {'cve_id': 'CVE-2024-52792',\n",
              "   'true': ['CWE-610'],\n",
              "   'pred_topk': ['CWE-13', 'CWE-473', 'CWE-616', 'CWE-11', 'CWE-98'],\n",
              "   'desc': 'LDAP Account Manager (LAM) is a php webfrontend for managing entries (e.g. users, groups, DHCP settings) stored in an LDAP directory. In affected versions LAM does not properly sanitize configuration values, that are set via `mainmanage.php` and `confmain.php`. This allows setting arbitrary config v'},\n",
              "  {'cve_id': 'CVE-2024-37226',\n",
              "   'true': ['CWE-862'],\n",
              "   'pred_topk': ['CWE-1220', 'CWE-1263', 'CWE-284', 'CWE-274', 'CWE-269'],\n",
              "   'desc': 'Missing Authorization vulnerability in Kanban for WordPress Kanban Boards for WordPress allows Exploiting Incorrectly Configured Access Control Security Levels.This issue affects Kanban Boards for WordPress: from n/a through 2.5.21.'},\n",
              "  {'cve_id': 'CVE-2023-23570',\n",
              "   'true': ['CWE-602'],\n",
              "   'pred_topk': ['CWE-565', 'CWE-784', 'CWE-472', 'CWE-446', 'CWE-11'],\n",
              "   'desc': 'Client-Side enforcement of Server-Side security for the Command Centre server could be bypassed and lead to invalid configuration with undefined behavior. \\n\\nThis issue affects: Gallagher Command Centre 8.90 prior to vEL8.90.1620 (MR2), all versions of 8.80 and prior.'},\n",
              "  {'cve_id': 'CVE-2025-1319',\n",
              "   'true': ['CWE-79'],\n",
              "   'pred_topk': ['CWE-85', 'CWE-692', 'CWE-81', 'CWE-80', 'CWE-87'],\n",
              "   'desc': 'The Site Mailer – SMTP Replacement, Email API Deliverability & Email Log plugin for WordPress is vulnerable to Stored Cross-Site Scripting in all versions up to, and including, 1.2.3 due to insufficient input sanitization and output escaping. This makes it possible for unauthenticated attackers to i'},\n",
              "  {'cve_id': 'CVE-2023-41134',\n",
              "   'true': ['CWE-290'],\n",
              "   'pred_topk': ['CWE-1390', 'CWE-1220', 'CWE-1263', 'CWE-784', 'CWE-497'],\n",
              "   'desc': 'Authentication Bypass by Spoofing vulnerability in pluginkollektiv Antispam Bee allows Accessing Functionality Not Properly Constrained by ACLs.This issue affects Antispam Bee: from n/a through 2.11.3.'},\n",
              "  {'cve_id': 'CVE-2022-0695',\n",
              "   'true': ['CWE-400'],\n",
              "   'pred_topk': ['CWE-1050', 'CWE-1325', 'CWE-410', 'CWE-1334', 'CWE-662'],\n",
              "   'desc': 'Denial of Service in GitHub repository radareorg/radare2 prior to 5.6.4.'},\n",
              "  {'cve_id': 'CVE-2023-0647',\n",
              "   'true': ['CWE-77'],\n",
              "   'pred_topk': ['CWE-537', 'CWE-114', 'CWE-84', 'CWE-305', 'CWE-1294'],\n",
              "   'desc': 'A vulnerability, which was classified as critical, has been found in dst-admin 1.5.0. Affected by this issue is some unknown functionality of the file /home/kickPlayer. The manipulation of the argument userId leads to command injection. The attack may be launched remotely. The exploit has been discl'},\n",
              "  {'cve_id': 'CVE-2025-24523',\n",
              "   'true': ['CWE-693'],\n",
              "   'pred_topk': ['CWE-645', 'CWE-1299', 'CWE-1259', 'CWE-307', 'CWE-1220'],\n",
              "   'desc': 'Protection mechanism failure for some Edge Orchestrator software before version 24.11.1 for Intel(R) Tiber(TM) Edge Platform may allow an authenticated user to potentially enable denial of service via adjacent access.'},\n",
              "  {'cve_id': 'CVE-2024-38061',\n",
              "   'true': ['CWE-284'],\n",
              "   'pred_topk': ['CWE-520', 'CWE-556', 'CWE-648', 'CWE-488', 'CWE-421'],\n",
              "   'desc': 'DCOM Remote Cross-Session Activation Elevation of Privilege Vulnerability'},\n",
              "  {'cve_id': 'CVE-2025-4680',\n",
              "   'true': ['CWE-20'],\n",
              "   'pred_topk': ['CWE-1220', 'CWE-1263', 'CWE-446', 'CWE-671', 'CWE-303'],\n",
              "   'desc': 'Improper Input Validation vulnerability in upKeeper Solutions upKeeper Instant Privilege Access allows Exploiting Incorrectly Configured Access Control Security Levels.This issue affects upKeeper Instant Privilege Access: before 1.4.0.'},\n",
              "  {'cve_id': 'CVE-2025-13497',\n",
              "   'true': ['CWE-79'],\n",
              "   'pred_topk': ['CWE-85', 'CWE-692', 'CWE-80', 'CWE-87', 'CWE-84'],\n",
              "   'desc': \"The Recras WordPress plugin for WordPress is vulnerable to Stored Cross-Site Scripting via the 'recrasname' shortcode attribute in all versions up to, and including, 6.4.1. This is due to insufficient input sanitization and output escaping. This makes it possible for authenticated attackers, with Co\"},\n",
              "  {'cve_id': 'CVE-2023-35989',\n",
              "   'true': ['CWE-190'],\n",
              "   'pred_topk': ['CWE-691', 'CWE-680', 'CWE-244', 'CWE-114', 'CWE-789'],\n",
              "   'desc': 'An integer overflow vulnerability exists in the LXT2 zlib block allocation functionality of GTKWave 3.3.115. A specially crafted .lxt2 file can lead to arbitrary code execution. A victim would need to open a malicious file to trigger this vulnerability.'},\n",
              "  {'cve_id': 'CVE-2024-38274',\n",
              "   'true': ['CWE-79'],\n",
              "   'pred_topk': ['CWE-85', 'CWE-692', 'CWE-81', 'CWE-87', 'CWE-83'],\n",
              "   'desc': 'Insufficient escaping of calendar event titles resulted in a stored XSS risk in the event deletion prompt.'},\n",
              "  {'cve_id': 'CVE-2022-25152',\n",
              "   'true': ['CWE-358'],\n",
              "   'pred_topk': ['CWE-1259', 'CWE-841', 'CWE-1189', 'CWE-114', 'CWE-784'],\n",
              "   'desc': 'The ITarian platform (SAAS / on-premise) offers the possibility to run code on agents via a function called procedures. It is possible to require a mandatory approval process. Due to a vulnerability in the approval process, present in any version prior to 6.35.37347.20040, a malicious actor (with a '},\n",
              "  {'cve_id': 'CVE-2025-9482',\n",
              "   'true': ['CWE-119', 'CWE-121'],\n",
              "   'pred_topk': ['CWE-1299', 'CWE-691', 'CWE-114', 'CWE-749', 'CWE-1320'],\n",
              "   'desc': 'A vulnerability was detected in Linksys RE6250, RE6300, RE6350, RE6500, RE7000 and RE9000 1.0.013.001/1.0.04.001/1.0.04.002/1.1.05.003/1.2.07.001. This impacts the function portRangeForwardAdd of the file /goform/portRangeForwardAdd. The manipulation of the argument ruleName/schedule/inboundFilter/T'},\n",
              "  {'cve_id': 'CVE-2025-1064',\n",
              "   'true': ['CWE-79'],\n",
              "   'pred_topk': ['CWE-84', 'CWE-85', 'CWE-692', 'CWE-81', 'CWE-472'],\n",
              "   'desc': \"The Login/Signup Popup ( Inline Form + Woocommerce ) plugin for WordPress is vulnerable to Stored Cross-Site Scripting via the plugin's xoo_el_action shortcode in all versions up to, and including, 2.8.5 due to insufficient input sanitization and output escaping on user supplied attributes. This mak\"}],\n",
              " 'hyde_enabled': True,\n",
              " 'hyde_used': 100,\n",
              " 'hyde_fail': 0,\n",
              " 'llm_model': 'mistral:7b-instruct',\n",
              " 'llm_used': 100,\n",
              " 'llm_top1_acc': 0.38,\n",
              " 'llm_top1_acc_overall': 0.38,\n",
              " 'llm_none': 0,\n",
              " 'llm_fail': 0}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TOP_K = 5\n",
        "MAX_RECORDS = 100   # requested: keep it quick; set None for all labeled CVEs\n",
        "SHUFFLE = True\n",
        "SEED = 42\n",
        "\n",
        "# LLM selector (Ollama)\n",
        "USE_LLM = True\n",
        "OLLAMA_MODEL = \"mistral:7b-instruct\"\n",
        "OLLAMA_TIMEOUT_S = 180\n",
        "\n",
        "# NEW Phase 3: HyDE (Hypothetical Document Embeddings)\n",
        "USE_HYDE = True  # Enable LLM-based HyDE: generate hypothetical CWE definition before RAG\n",
        "HYDE_TIMEOUT_S = 60\n",
        "\n",
        "records = list(iter_labeled_cves(CVE_ROOT))\n",
        "print(\"Total labeled CVEs found:\", len(records))\n",
        "\n",
        "if SHUFFLE:\n",
        "    random.Random(SEED).shuffle(records)\n",
        "\n",
        "if MAX_RECORDS is not None:\n",
        "    records = records[:MAX_RECORDS]\n",
        "\n",
        "print(\"Evaluating:\", len(records), \"records\")\n",
        "\n",
        "\n",
        "def ollama_available() -> bool:\n",
        "    return shutil.which(\"ollama\") is not None\n",
        "\n",
        "\n",
        "def build_llm_prompt(cve_description: str, candidates: list[dict]) -> str:\n",
        "    lines = []\n",
        "    lines.append(\"You are a security analyst.\")\n",
        "    lines.append(\"Return ONLY valid JSON. Do not wrap it in markdown.\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"VULNERABILITY DESCRIPTION:\")\n",
        "    lines.append((cve_description or \"\").strip())\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"CANDIDATE CWE DEFINITIONS:\")\n",
        "\n",
        "    for i, c in enumerate(candidates, start=1):\n",
        "        lines.append(\"\")\n",
        "        lines.append(f\"{i}. {c['cwe_id']} — {c.get('name','')}\")\n",
        "        lines.append(f\"Definition: {c.get('description','')}\")\n",
        "\n",
        "    lines.append(\"\")\n",
        "    lines.append(\n",
        "        \"Task: Choose the SINGLE best CWE from the candidates. \"\n",
        "        \"If none fit well, output best_cwe as 'NONE'. \"\n",
        "        \"Respond in JSON with keys: best_cwe, confidence (0..1), rationale.\"\n",
        "    )\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def run_ollama(prompt: str, model: str, timeout_s: int):\n",
        "    proc = subprocess.run(\n",
        "        [\"ollama\", \"run\", model],\n",
        "        input=prompt.encode(\"utf-8\"),\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        timeout=timeout_s,\n",
        "    )\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(proc.stderr.decode(\"utf-8\", errors=\"ignore\"))\n",
        "    return proc.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
        "\n",
        "\n",
        "def parse_llm_json(text: str) -> dict | None:\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    # Try to extract the first JSON object from the output\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
        "    if not m:\n",
        "        return None\n",
        "\n",
        "    blob = m.group(0)\n",
        "    try:\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_cwe(s: str | None) -> str | None:\n",
        "    if not s:\n",
        "        return None\n",
        "    s = str(s).strip().upper()\n",
        "    if s == \"NONE\":\n",
        "        return \"NONE\"\n",
        "\n",
        "    # Accept formats like \"CWE-79\" or \"79\"\n",
        "    if re.fullmatch(r\"CWE-\\d+\", s):\n",
        "        return s\n",
        "    if re.fullmatch(r\"\\d+\", s):\n",
        "        return f\"CWE-{s}\"\n",
        "\n",
        "    # last resort: search inside\n",
        "    m = re.search(r\"CWE-\\d+\", s)\n",
        "    return m.group(0) if m else None\n",
        "\n",
        "\n",
        "def build_hyde_prompt(cve_description: str) -> str:\n",
        "    \"\"\"Build HyDE prompt to generate a hypothetical CWE definition from CVE description.\"\"\"\n",
        "    lines = []\n",
        "    lines.append(\"You are a CWE (Common Weakness Enumeration) author writing weakness definitions.\")\n",
        "    lines.append(\"Return ONLY the weakness definition text. Do not add explanations or markdown.\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"TASK: Given this vulnerability instance, write a CWE-style weakness definition.\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"VULNERABILITY INSTANCE:\")\n",
        "    lines.append(cve_description.strip() if cve_description else \"(missing)\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"INSTRUCTIONS:\")\n",
        "    lines.append(\"- Write in CWE style: describe the weakness TYPE, not the specific instance\")\n",
        "    lines.append(\"- Start with 'The product...' or 'The software...' (like real CWE definitions)\")\n",
        "    lines.append(\"- Remove specific product names and versions\")\n",
        "    lines.append(\"- Focus on what the SOFTWARE does wrong (not what attackers do)\")\n",
        "    lines.append(\"- Use CWE terminology: 'improper validation', 'insufficient verification', etc.\")\n",
        "    lines.append(\"- Keep it 2-4 sentences\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"Example:\")\n",
        "    lines.append(\"  CVE: 'SQL injection in login.php via username parameter'\")\n",
        "    lines.append(\"  CWE-style: 'The product constructs SQL queries using externally-influenced input without proper neutralization of special elements, allowing attackers to modify the intended SQL command structure.'\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"WEAKNESS DEFINITION:\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def generate_hyde_document(cve_description: str, model: str, timeout_s: int = 60):\n",
        "    \"\"\"Use Ollama to generate hypothetical CWE definition from CVE description (HyDE).\n",
        "    \n",
        "    Returns: hyde_definition or None if fails\n",
        "    \"\"\"\n",
        "    if not ollama_available():\n",
        "        return None\n",
        "    \n",
        "    prompt = build_hyde_prompt(cve_description)\n",
        "    \n",
        "    try:\n",
        "        proc = subprocess.run(\n",
        "            [\"ollama\", \"run\", model],\n",
        "            input=prompt.encode(\"utf-8\"),\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            timeout=timeout_s,\n",
        "        )\n",
        "        if proc.returncode != 0:\n",
        "            return None\n",
        "        \n",
        "        raw_output = proc.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
        "        \n",
        "        # Clean up: remove any markdown formatting or extra explanations\n",
        "        hyde_def = raw_output.strip()\n",
        "        \n",
        "        # If LLM added markdown code blocks, extract the content\n",
        "        if hyde_def.startswith(\"```\"):\n",
        "            lines = hyde_def.split(\"\\n\")\n",
        "            hyde_def = \"\\n\".join([l for l in lines if not l.strip().startswith(\"```\")])\n",
        "        \n",
        "        hyde_def = hyde_def.strip()\n",
        "        \n",
        "        return hyde_def if hyde_def else None\n",
        "        \n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def predict_topk_from_description(desc: str, k: int = 5):\n",
        "    idx_scores = retrieve_topk(desc, k=k)\n",
        "    preds = []\n",
        "    for idx, score in idx_scores:\n",
        "        c = cwe_corpus[idx]\n",
        "        preds.append({\n",
        "            \"cwe_id\": c[\"id\"],\n",
        "            \"score\": float(score),\n",
        "            \"name\": c[\"name\"],\n",
        "            \"description\": c[\"description\"],\n",
        "        })\n",
        "    return preds\n",
        "\n",
        "\n",
        "def llm_choose_best_cwe(desc: str, candidates: list[dict]):\n",
        "    \"\"\"Return chosen CWE id (CWE-123 / NONE) and raw model output.\"\"\"\n",
        "    prompt = build_llm_prompt(desc, candidates)\n",
        "    out = run_ollama(prompt, model=OLLAMA_MODEL, timeout_s=OLLAMA_TIMEOUT_S)\n",
        "    parsed = parse_llm_json(out)\n",
        "    best = normalize_cwe(parsed.get(\"best_cwe\") if parsed else None)\n",
        "    return best, out\n",
        "\n",
        "\n",
        "def evaluate(records, k: int = 5, progress_every: int = 20):\n",
        "    t0 = time.time()\n",
        "\n",
        "    n = 0\n",
        "    top1_correct = 0\n",
        "    topk_correct = 0\n",
        "\n",
        "    llm_used = 0\n",
        "    llm_correct = 0\n",
        "    llm_none = 0\n",
        "    llm_fail = 0\n",
        "    \n",
        "    # NEW: HyDE tracking\n",
        "    hyde_used = 0\n",
        "    hyde_fail = 0\n",
        "\n",
        "    # optional: keep some mistakes for inspection\n",
        "    mistakes = []\n",
        "\n",
        "    if USE_LLM and not ollama_available():\n",
        "        print(\"WARNING: USE_LLM=True but 'ollama' was not found on PATH; disabling LLM evaluation.\")\n",
        "    \n",
        "    if USE_HYDE and not ollama_available():\n",
        "        print(\"WARNING: USE_HYDE=True but 'ollama' was not found on PATH; disabling HyDE.\")\n",
        "\n",
        "    use_llm = USE_LLM and ollama_available()\n",
        "    use_hyde = USE_HYDE and ollama_available()\n",
        "\n",
        "    for r in records:\n",
        "        n += 1\n",
        "        true_set = set(r[\"true_cwes\"])\n",
        "        \n",
        "        # NEW: Apply HyDE before retrieval if enabled\n",
        "        query_for_retrieval = r[\"description\"]\n",
        "        if use_hyde:\n",
        "            hyde_doc = generate_hyde_document(r[\"description\"], model=OLLAMA_MODEL, timeout_s=HYDE_TIMEOUT_S)\n",
        "            if hyde_doc:\n",
        "                query_for_retrieval = hyde_doc\n",
        "                hyde_used += 1\n",
        "            else:\n",
        "                hyde_fail += 1\n",
        "                # Fallback to original description\n",
        "        \n",
        "        preds = predict_topk_from_description(query_for_retrieval, k=k)\n",
        "\n",
        "        pred_ids = [p[\"cwe_id\"] for p in preds]\n",
        "        top1 = pred_ids[0] if pred_ids else None\n",
        "\n",
        "        if top1 in true_set:\n",
        "            top1_correct += 1\n",
        "\n",
        "        if any(pid in true_set for pid in pred_ids):\n",
        "            topk_correct += 1\n",
        "        else:\n",
        "            if len(mistakes) < 20:\n",
        "                mistakes.append({\n",
        "                    \"cve_id\": r[\"cve_id\"],\n",
        "                    \"true\": r[\"true_cwes\"],\n",
        "                    \"pred_topk\": pred_ids,\n",
        "                    \"desc\": r[\"description\"][:300],\n",
        "                })\n",
        "\n",
        "        # LLM selector accuracy (choose 1 from the top-k candidates)\n",
        "        if use_llm and preds:\n",
        "            try:\n",
        "                llm_used += 1\n",
        "                best_cwe, raw = llm_choose_best_cwe(r[\"description\"], preds)\n",
        "                if best_cwe == \"NONE\":\n",
        "                    llm_none += 1\n",
        "                elif best_cwe in true_set:\n",
        "                    llm_correct += 1\n",
        "            except Exception:\n",
        "                llm_fail += 1\n",
        "\n",
        "        if progress_every and n % progress_every == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            msg = f\"[{n}/{len(records)}] top1={top1_correct/n:.3f} top{k}={topk_correct/n:.3f}\"\n",
        "            if use_hyde:\n",
        "                msg += f\" hyde={hyde_used}/{n} (fail={hyde_fail})\"\n",
        "            if use_llm:\n",
        "                llm_acc = (llm_correct / llm_used) if llm_used else 0.0\n",
        "                msg += f\" llm_top1={llm_acc:.3f} (used={llm_used}, none={llm_none}, fail={llm_fail})\"\n",
        "            msg += f\" elapsed={elapsed:.1f}s\"\n",
        "            print(msg)\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    out = {\n",
        "        \"n\": n,\n",
        "        \"top1_acc\": top1_correct / n if n else 0.0,\n",
        "        f\"top{k}_acc\": topk_correct / n if n else 0.0,\n",
        "        \"elapsed_s\": elapsed,\n",
        "        \"backend\": RETRIEVER_BACKEND,\n",
        "        \"mistakes_sample\": mistakes,\n",
        "    }\n",
        "    \n",
        "    if use_hyde:\n",
        "        out.update({\n",
        "            \"hyde_enabled\": True,\n",
        "            \"hyde_used\": hyde_used,\n",
        "            \"hyde_fail\": hyde_fail,\n",
        "        })\n",
        "\n",
        "    if use_llm:\n",
        "        out.update({\n",
        "            \"llm_model\": OLLAMA_MODEL,\n",
        "            \"llm_used\": llm_used,\n",
        "            \"llm_top1_acc\": (llm_correct / llm_used) if llm_used else 0.0,\n",
        "            \"llm_top1_acc_overall\": (llm_correct / n) if n else 0.0,\n",
        "            \"llm_none\": llm_none,\n",
        "            \"llm_fail\": llm_fail,\n",
        "        })\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "metrics = evaluate(records, k=TOP_K)\n",
        "metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fortiss_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
