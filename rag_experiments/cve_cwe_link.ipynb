{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVE to CWE Linker\n",
    "This notebook provides a tool to link a CVE ID to its associated CWEs and display their names and descriptions using the local CVE and CWE databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/dnfy/Desktop/Fortiss\n",
      "CWE Database: /home/dnfy/Desktop/Fortiss/data/cwec_v4.19.xml\n",
      "CVE Database Directory: /home/dnfy/Desktop/Fortiss/data/cvelistV5-main/cves\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Project-relative paths (assumes you run the notebook from the repo root)\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "CWE_XML_PATH = PROJECT_ROOT / \"data\" / \"cwec_v4.19.xml\"\n",
    "CVE_BASE_DIR = PROJECT_ROOT / \"data\" / \"cvelistV5-main\" / \"cves\"\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"CWE Database: {CWE_XML_PATH}\")\n",
    "print(f\"CVE Database Directory: {CVE_BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse CWE Database\n",
    "We parse the CWE XML file to create a mapping from CWE ID to its name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 969 CWEs from cwec_v4.19.xml.\n"
     ]
    }
   ],
   "source": [
    "def parse_cwe_database(xml_path: Path):\n",
    "    \"\"\"Parse CWE XML into:\n",
    "    - cwe_map: CWE-<id> -> {name, description}\n",
    "    - cwe_corpus: list[{id, name, description, text}] for retrieval\n",
    "\n",
    "    Note: This catalog is ~1k weaknesses, so a full parse is OK.\n",
    "    \"\"\"\n",
    "    cwe_map = {}\n",
    "    cwe_corpus = []\n",
    "\n",
    "    xml_path = Path(xml_path)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract namespace if present\n",
    "    ns = {\"cwe\": root.tag.split(\"}\")[0].strip(\"{\")} if \"}\" in root.tag else {}\n",
    "    xpath = \".//cwe:Weakness\" if ns else \".//Weakness\"\n",
    "\n",
    "    for weakness in root.findall(xpath, ns):\n",
    "        wid = weakness.get(\"ID\")\n",
    "        wname = weakness.get(\"Name\")\n",
    "\n",
    "        desc_elem = weakness.find(\"cwe:Description\", ns) if ns else weakness.find(\"Description\")\n",
    "        description = (desc_elem.text or \"\").strip() if desc_elem is not None else \"\"\n",
    "        if not description:\n",
    "            description = \"No description available.\"\n",
    "\n",
    "        cwe_id = f\"CWE-{wid}\"\n",
    "        cwe_map[cwe_id] = {\"name\": wname, \"description\": description}\n",
    "\n",
    "        # Retrieval text: keep it simple and dense\n",
    "        text = f\"{cwe_id}: {wname}. {description}\"\n",
    "        cwe_corpus.append({\"id\": cwe_id, \"name\": wname, \"description\": description, \"text\": text})\n",
    "\n",
    "    print(f\"Successfully parsed {len(cwe_map)} CWEs from {xml_path.name}.\")\n",
    "    return cwe_map, cwe_corpus\n",
    "\n",
    "cwe_map, cwe_corpus = parse_cwe_database(CWE_XML_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Hybrid RAG: Build a Retriever Index (offline fallback)\n",
    "\n",
    "This notebook supports two retriever backends:\n",
    "- **Preferred**: `sentence-transformers/all-mpnet-base-v2` embeddings + FAISS/Chroma (if installed).\n",
    "- **Fallback (works offline here)**: lightweight **TF‑IDF + cosine similarity** using `scipy`.\n",
    "\n",
    "The output is the same: given a CVE description, retrieve the top‑k closest CWE definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF index built: X=(969, 3681), vocab=3681 tokens\n",
      "Retriever backend: tfidf\n"
     ]
    }
   ],
   "source": [
    "def _normalize_text(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    # keep letters/digits, turn the rest into spaces\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _tokenize(s: str):\n",
    "    # very simple tokenizer (fast + deterministic)\n",
    "    s = _normalize_text(s)\n",
    "    return [t for t in s.split(\" \") if t]\n",
    "\n",
    "\n",
    "def build_tfidf_index(corpus_texts):\n",
    "    \"\"\"Build a TF-IDF (L2-normalized) sparse matrix.\n",
    "\n",
    "    Returns: (X, vocab)\n",
    "      - X: shape (n_docs, n_terms)\n",
    "      - vocab: token -> column index\n",
    "    \"\"\"\n",
    "    n_docs = len(corpus_texts)\n",
    "\n",
    "    # 1) collect term counts per doc + document frequency\n",
    "    doc_term_counts = []\n",
    "    df = {}\n",
    "\n",
    "    for text in corpus_texts:\n",
    "        counts = {}\n",
    "        for tok in _tokenize(text):\n",
    "            counts[tok] = counts.get(tok, 0) + 1\n",
    "        doc_term_counts.append(counts)\n",
    "        for tok in counts.keys():\n",
    "            df[tok] = df.get(tok, 0) + 1\n",
    "\n",
    "    # 2) build vocab\n",
    "    vocab = {tok: i for i, tok in enumerate(sorted(df.keys()))}\n",
    "    n_terms = len(vocab)\n",
    "\n",
    "    # 3) build sparse TF matrix\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for r, counts in enumerate(doc_term_counts):\n",
    "        for tok, tf in counts.items():\n",
    "            c = vocab[tok]\n",
    "            rows.append(r)\n",
    "            cols.append(c)\n",
    "            vals.append(float(tf))\n",
    "\n",
    "    tf = sp.csr_matrix((vals, (rows, cols)), shape=(n_docs, n_terms), dtype=np.float32)\n",
    "\n",
    "    # 4) idf\n",
    "    # smooth: idf = log((1+n)/(1+df)) + 1\n",
    "    idf = np.empty(n_terms, dtype=np.float32)\n",
    "    for tok, c in vocab.items():\n",
    "        idf[c] = math.log((1.0 + n_docs) / (1.0 + df[tok])) + 1.0\n",
    "\n",
    "    X = tf.multiply(idf)\n",
    "\n",
    "    # 5) L2 normalize rows for cosine similarity\n",
    "    row_norm = np.sqrt(X.multiply(X).sum(axis=1)).A1\n",
    "    row_norm[row_norm == 0] = 1.0\n",
    "    X = sp.diags(1.0 / row_norm).dot(X)\n",
    "\n",
    "    return X, vocab\n",
    "\n",
    "\n",
    "def tfidf_query(text: str, vocab, idf_vec):\n",
    "    counts = {}\n",
    "    for tok in _tokenize(text):\n",
    "        if tok in vocab:\n",
    "            counts[tok] = counts.get(tok, 0) + 1\n",
    "\n",
    "    if not counts:\n",
    "        return sp.csr_matrix((1, len(vocab)), dtype=np.float32)\n",
    "\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for tok, tf in counts.items():\n",
    "        c = vocab[tok]\n",
    "        rows.append(0)\n",
    "        cols.append(c)\n",
    "        vals.append(float(tf))\n",
    "\n",
    "    q_tf = sp.csr_matrix((vals, (rows, cols)), shape=(1, len(vocab)), dtype=np.float32)\n",
    "    q = q_tf.multiply(idf_vec)\n",
    "\n",
    "    q_norm = np.sqrt(q.multiply(q).sum(axis=1)).A1\n",
    "    q_norm[q_norm == 0] = 1.0\n",
    "    q = q.multiply(1.0 / q_norm[0])\n",
    "\n",
    "    return q\n",
    "\n",
    "\n",
    "# Build the fallback retriever index now\n",
    "_cwe_texts = [c[\"text\"] for c in cwe_corpus]\n",
    "X_tfidf, vocab = build_tfidf_index(_cwe_texts)\n",
    "\n",
    "# Precompute idf vector in vocab order for queries\n",
    "idf_vec = np.ones(len(vocab), dtype=np.float32)\n",
    "# reconstruct df from matrix is annoying; easiest is to re-derive from corpus (small)\n",
    "# so we reuse the same idf formula here:\n",
    "_df = {tok: 0 for tok in vocab.keys()}\n",
    "for text in _cwe_texts:\n",
    "    seen = set(_tokenize(text))\n",
    "    for tok in seen:\n",
    "        if tok in _df:\n",
    "            _df[tok] += 1\n",
    "n_docs = len(_cwe_texts)\n",
    "for tok, c in vocab.items():\n",
    "    idf_vec[c] = math.log((1.0 + n_docs) / (1.0 + _df[tok])) + 1.0\n",
    "\n",
    "print(f\"TF-IDF index built: X={X_tfidf.shape}, vocab={len(vocab)} tokens\")\n",
    "\n",
    "\n",
    "def retrieve_cwe_candidates(query_text: str, top_k: int = 5):\n",
    "    \"\"\"Retriever step: returns top_k CWE candidates with similarity scores.\n",
    "\n",
    "    Default backend: TF-IDF cosine (works offline).\n",
    "    If you install sentence-transformers, we auto-upgrade to SBERT cosine.\n",
    "    \"\"\"\n",
    "\n",
    "    q = tfidf_query(query_text, vocab, idf_vec)\n",
    "\n",
    "    # cosine similarity since both are normalized\n",
    "    sims = (X_tfidf @ q.T).toarray().ravel()\n",
    "    if sims.size == 0:\n",
    "        return []\n",
    "\n",
    "    top_idx = np.argsort(-sims)[:top_k]\n",
    "    results = []\n",
    "    for i in top_idx:\n",
    "        c = cwe_corpus[int(i)]\n",
    "        results.append({\n",
    "            \"cwe_id\": c[\"id\"],\n",
    "            \"score\": float(sims[int(i)]),\n",
    "            \"name\": c[\"name\"],\n",
    "            \"description\": c[\"description\"],\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- Optional: preferred semantic retriever (SBERT) ---\n",
    "RETRIEVER_BACKEND = \"tfidf\"\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    _sbert_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    _cwe_emb = _sbert_model.encode(_cwe_texts, normalize_embeddings=True, show_progress_bar=True)\n",
    "    RETRIEVER_BACKEND = \"sbert\"\n",
    "\n",
    "    def retrieve_cwe_candidates(query_text: str, top_k: int = 5):\n",
    "        \"\"\"Retriever step (SBERT): embed query, cosine against CWE embeddings.\"\"\"\n",
    "        q = _sbert_model.encode([query_text], normalize_embeddings=True)[0]\n",
    "        sims = _cwe_emb @ q\n",
    "        top_idx = np.argsort(-sims)[:top_k]\n",
    "        results = []\n",
    "        for i in top_idx:\n",
    "            c = cwe_corpus[int(i)]\n",
    "            results.append({\n",
    "                \"cwe_id\": c[\"id\"],\n",
    "                \"score\": float(sims[int(i)]),\n",
    "                \"name\": c[\"name\"],\n",
    "                \"description\": c[\"description\"],\n",
    "            })\n",
    "        return results\n",
    "\n",
    "except Exception:\n",
    "    # sentence-transformers not installed (or model not available). Keep TF-IDF backend.\n",
    "    pass\n",
    "\n",
    "print(f\"Retriever backend: {RETRIEVER_BACKEND}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Link CVE to CWE\n",
    "Function to find the CVE JSON file and extract CWE IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cve_id(cve_input: str):\n",
    "    m = re.search(r\"(CVE-\\d{4}-\\d+)\", (cve_input or \"\").upper())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def get_cve_path(cve_id: str) -> Path | None:\n",
    "    \"\"\"Construct the CVE JSON path for cvelistV5 layout: <year>/<prefix>xxx/CVE-YYYY-NNNN.json\"\"\"\n",
    "    cve_id = (cve_id or \"\").upper()\n",
    "    match = re.match(r\"CVE-(\\d{4})-(\\d+)$\", cve_id)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    year = match.group(1)\n",
    "    number = match.group(2)\n",
    "\n",
    "    # Directory is the number with last 3 digits replaced by 'xxx'\n",
    "    # 0001 -> 0xxx, 1234 -> 1xxx, 12345 -> 12xxx\n",
    "    if len(number) < 4:\n",
    "        dir_name = \"0xxx\"\n",
    "    else:\n",
    "        dir_name = number[:-3] + \"xxx\"\n",
    "\n",
    "    return CVE_BASE_DIR / year / dir_name / f\"{cve_id}.json\"\n",
    "\n",
    "\n",
    "def read_cve_record(cve_input: str):\n",
    "    \"\"\"Return (cve_id, data_dict) or (cve_id, error_str).\"\"\"\n",
    "    cve_id = normalize_cve_id(cve_input)\n",
    "    if not cve_id:\n",
    "        return None, \"Invalid CVE ID or link.\"\n",
    "\n",
    "    cve_path = get_cve_path(cve_id)\n",
    "    if not cve_path:\n",
    "        return cve_id, f\"Could not map CVE to path: {cve_id}\"\n",
    "\n",
    "    if not cve_path.exists():\n",
    "        return cve_id, f\"CVE file not found at {cve_path}\"\n",
    "\n",
    "    with cve_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return cve_id, data\n",
    "\n",
    "\n",
    "def extract_cves_explicit_cwes(cve_data: dict):\n",
    "    \"\"\"Extract explicit CWE IDs from CVE JSON (containers.cna.problemTypes.*.descriptions[].cweId).\"\"\"\n",
    "    cwe_ids = []\n",
    "    problem_types = cve_data.get(\"containers\", {}).get(\"cna\", {}).get(\"problemTypes\", [])\n",
    "    for pt in problem_types:\n",
    "        for desc in pt.get(\"descriptions\", []):\n",
    "            cwe_id = desc.get(\"cweId\")\n",
    "            if cwe_id and isinstance(cwe_id, str) and cwe_id.startswith(\"CWE-\"):\n",
    "                cwe_ids.append(cwe_id)\n",
    "    return sorted(set(cwe_ids))\n",
    "\n",
    "\n",
    "def extract_cve_description(cve_data: dict) -> str:\n",
    "    \"\"\"Best-effort: get the English description from CVE V5.\"\"\"\n",
    "    descs = cve_data.get(\"containers\", {}).get(\"cna\", {}).get(\"descriptions\", [])\n",
    "    for d in descs:\n",
    "        if d.get(\"lang\") == \"en\" and d.get(\"value\"):\n",
    "            return str(d.get(\"value\")).strip()\n",
    "\n",
    "    # fallback: any description\n",
    "    for d in descs:\n",
    "        if d.get(\"value\"):\n",
    "            return str(d.get(\"value\")).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def retrieve_cwes_for_cve(cve_data: dict, top_k: int = 5, use_hyde: bool = False, ollama_model: str = \"mistral:7b-instruct\"):\n",
    "    \"\"\"Hybrid step: if explicit CWEs exist, return those; otherwise retrieve based on description.\n",
    "    \n",
    "    NEW (Phase 3 - HyDE): If use_hyde=True, generates hypothetical CWE definition before retrieval.\n",
    "    \"\"\"\n",
    "    explicit = extract_cves_explicit_cwes(cve_data)\n",
    "    desc = extract_cve_description(cve_data)\n",
    "\n",
    "    if explicit:\n",
    "        return {\n",
    "            \"mode\": \"explicit\",\n",
    "            \"cve_description\": desc,\n",
    "            \"explicit_cwes\": explicit,\n",
    "            \"retrieved\": retrieve_cwe_candidates(desc, top_k=top_k) if desc else [],\n",
    "            \"hyde_document\": None,\n",
    "        }\n",
    "\n",
    "    if not desc:\n",
    "        return {\"mode\": \"none\", \"cve_description\": \"\", \"explicit_cwes\": [], \"retrieved\": [], \"hyde_document\": None}\n",
    "\n",
    "    # NEW: HyDE step - generate hypothetical CWE definition\n",
    "    query_for_retrieval = desc\n",
    "    hyde_document = None\n",
    "    \n",
    "    if use_hyde:\n",
    "        hyde_def, _ = generate_hyde_document(desc, model=ollama_model)\n",
    "        if hyde_def:\n",
    "            hyde_document = hyde_def\n",
    "            query_for_retrieval = hyde_def\n",
    "            print(f\"[HyDE] CVE: {desc[:80]}...\")\n",
    "            print(f\"[HyDE] Generated CWE: {hyde_def[:80]}...\")\n",
    "\n",
    "    return {\n",
    "        \"mode\": \"rag_hyde\" if use_hyde else \"rag\",\n",
    "        \"cve_description\": desc,\n",
    "        \"explicit_cwes\": [],\n",
    "        \"retrieved\": retrieve_cwe_candidates(query_for_retrieval, top_k=top_k),\n",
    "        \"hyde_document\": hyde_document,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. HyDE Step (NEW - Phase 3): Hypothetical Document Embeddings\n",
    "\n",
    "**HyDE (Hypothetical Document Embeddings)** approach:\n",
    "- Instead of abstracting the CVE, generate a **hypothetical CWE definition**\n",
    "- LLM writes what a CWE entry would look like for this vulnerability\n",
    "- Use that generated definition for retrieval\n",
    "\n",
    "**Why this should work better than abstraction:**\n",
    "- Matches CWE writing style and vocabulary\n",
    "- Uses CWE-specific terminology\n",
    "- Same document type (definition → definition) instead of (description → definition)\n",
    "\n",
    "**Example:**\n",
    "- CVE: \"Buffer overflow in libpng 1.2.3 allows remote code execution\"\n",
    "- HyDE generates: \"The product writes data past the end of a buffer, allowing attackers to execute arbitrary code...\"\n",
    "- This matches how CWE-787 is actually written!\n",
    "\n",
    "## 2c. Reasoner Step (Optional): Local LLM\n",
    "\n",
    "If you have a local LLM runner (e.g., **Ollama**) you can let it choose the best CWE among the retrieved candidates.\n",
    "\n",
    "Prompt template:\n",
    "\n",
    "\"Given this vulnerability description and these 5 potential weakness definitions, which one fits best? If none fit well, look at the parents of these CWEs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hyde_prompt(cve_description: str) -> str:\n",
    "    \"\"\"Build HyDE prompt to generate a hypothetical CWE definition from CVE description.\"\"\"\n",
    "    lines = []\n",
    "    lines.append(\"You are a CWE (Common Weakness Enumeration) author writing weakness definitions.\")\n",
    "    lines.append(\"Return ONLY the weakness definition text. Do not add explanations or markdown.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"TASK: Given this vulnerability instance, write a CWE-style weakness definition.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"VULNERABILITY INSTANCE:\")\n",
    "    lines.append(cve_description.strip() if cve_description else \"(missing)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"INSTRUCTIONS:\")\n",
    "    lines.append(\"- Write in CWE style: describe the weakness TYPE, not the specific instance\")\n",
    "    lines.append(\"- Start with 'The product...' or 'The software...' (like real CWE definitions)\")\n",
    "    lines.append(\"- Remove specific product names and versions\")\n",
    "    lines.append(\"- Focus on what the SOFTWARE does wrong (not what attackers do)\")\n",
    "    lines.append(\"- Use CWE terminology: 'improper validation', 'insufficient verification', etc.\")\n",
    "    lines.append(\"- Keep it 2-4 sentences\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Example:\")\n",
    "    lines.append(\"  CVE: 'SQL injection in login.php via username parameter'\")\n",
    "    lines.append(\"  CWE-style: 'The product constructs SQL queries using externally-influenced input without proper neutralization of special elements, allowing attackers to modify the intended SQL command structure.'\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"WEAKNESS DEFINITION:\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def generate_hyde_document(cve_description: str, model: str = \"mistral:7b-instruct\", timeout_s: int = 60):\n",
    "    \"\"\"Use Ollama to generate hypothetical CWE definition from CVE description (HyDE).\n",
    "    \n",
    "    Returns: (hyde_definition, raw_output) or (None, None) if fails\n",
    "    \"\"\"\n",
    "    if not ollama_available():\n",
    "        return None, None\n",
    "    \n",
    "    prompt = build_hyde_prompt(cve_description)\n",
    "    \n",
    "    try:\n",
    "        proc = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout_s,\n",
    "        )\n",
    "        if proc.returncode != 0:\n",
    "            print(f\"Ollama error: {proc.stderr.decode('utf-8', errors='ignore')}\")\n",
    "            return None, None\n",
    "        \n",
    "        raw_output = proc.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "        \n",
    "        # Clean up: remove any markdown formatting or extra explanations\n",
    "        hyde_def = raw_output.strip()\n",
    "        \n",
    "        # If LLM added markdown code blocks, extract the content\n",
    "        if hyde_def.startswith(\"```\"):\n",
    "            lines = hyde_def.split(\"\\n\")\n",
    "            hyde_def = \"\\n\".join([l for l in lines if not l.strip().startswith(\"```\")])\n",
    "        \n",
    "        hyde_def = hyde_def.strip()\n",
    "        \n",
    "        return hyde_def, raw_output\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Ollama timeout during HyDE generation\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama HyDE generation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Test example (only runs if ollama is available)\n",
    "if ollama_available():\n",
    "    test_cve_desc = \"A buffer overflow vulnerability in libpng version 1.2.3 allows remote attackers to execute arbitrary code via a crafted PNG file.\"\n",
    "    hyde_def, raw = generate_hyde_document(test_cve_desc)\n",
    "    \n",
    "    if hyde_def:\n",
    "        print(\"=== HyDE TEST ===\")\n",
    "        print(\"CVE Description:\")\n",
    "        print(test_cve_desc)\n",
    "        print(\"\\nGenerated CWE-style Definition:\")\n",
    "        print(hyde_def)\n",
    "        print(\"\\n=== END TEST ===\")\n",
    "else:\n",
    "    print(\"Ollama not available; HyDE will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reasoner_prompt(cve_description: str, candidates: list[dict], top_k: int = 5) -> str:\n",
    "    \"\"\"Build a single prompt for an instruction-tuned LLM (e.g., mistral:7b-instruct).\"\"\"\n",
    "    lines = []\n",
    "    lines.append(\"You are a security analyst.\")\n",
    "    lines.append(\"Return ONLY valid JSON. Do not wrap it in markdown.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"VULNERABILITY DESCRIPTION:\")\n",
    "    lines.append(cve_description.strip() if cve_description else \"(missing)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"TOP {top_k} RETRIEVED CWE DEFINITIONS:\")\n",
    "\n",
    "    for i, c in enumerate(candidates[:top_k], start=1):\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"{i}. {c['cwe_id']} — {c.get('name','')}\")\n",
    "        lines.append(f\"Definition: {c.get('description','')}\")\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\n",
    "        \"Task: Given the vulnerability description and the candidate CWE definitions, choose the SINGLE best CWE. \"\n",
    "        \"If none fit well, output best_cwe as 'NONE'. \"\n",
    "        \"If NONE, suggest which parent(s) to check and why (in the rationale).\\n\\n\"\n",
    "        \"Output schema (JSON): {\\\"best_cwe\\\": <CWE-XXX or NONE>, \\\"confidence\\\": <0..1>, \\\"rationale\\\": <string>}\"\n",
    "    )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def ollama_available() -> bool:\n",
    "    return shutil.which(\"ollama\") is not None\n",
    "\n",
    "\n",
    "def run_ollama_reasoner(prompt: str, model: str = \"mistral:7b-instruct\", timeout_s: int = 180):\n",
    "    \"\"\"Runs ollama if installed. Returns stdout text or None.\"\"\"\n",
    "    if not ollama_available():\n",
    "        return None\n",
    "\n",
    "    # Non-interactive: pass prompt via stdin\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(\"utf-8\"),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        timeout=timeout_s,\n",
    "    )\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr.decode(\"utf-8\", errors=\"ignore\"))\n",
    "        return None\n",
    "\n",
    "    return proc.stdout.decode(\"utf-8\", errors=\"ignore\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Tool\n",
    "Input a CVE link or ID to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Hybrid results for CVE-2024-0001 ###\n",
      "\n",
      "CVE description:\n",
      "A condition exists in FlashArray Purity whereby a local account intended for initial array configuration remains active potentially allowing a malicious actor to gain elevated privileges.\n",
      "\n",
      "Explicit CWEs in CVE record:\n",
      "- CWE-1188: Initialization of a Resource with an Insecure Default\n",
      "  Description: The product initializes or sets a resource with a default that is intended to be changed by the product's installer, administrator, or maintainer, but the default is not secure.\n",
      "\n",
      "Retriever top-5 CWE candidates (cosine similarity):\n",
      "- CWE-496 (score=0.1729) — Public Data Assigned to Private Array-Typed Field\n",
      "- CWE-489 (score=0.1692) — Active Debug Code\n",
      "- CWE-648 (score=0.1597) — Incorrect Use of Privileged APIs\n",
      "- CWE-582 (score=0.1594) — Array Declared Public, Final, and Static\n",
      "- CWE-129 (score=0.1524) — Improper Validation of Array Index\n",
      "\n",
      "LLM reasoner output:\n",
      "\n",
      "{\n",
      "  \"best_cwe\": \"CWE-648\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"rationale\": \"The vulnerability description mentions a condition where the product does not conform to the API requirements for a function call that requires extra privileges. This aligns with CWE-648: Incorrect Use of Privileged APIs.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_cwe(cwe_id: str):\n",
    "    info = cwe_map.get(cwe_id)\n",
    "    if not info:\n",
    "        print(f\"- {cwe_id}: (not found in CWE catalog)\")\n",
    "        return\n",
    "    print(f\"- {cwe_id}: {info['name']}\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "\n",
    "\n",
    "def lookup_cve_hybrid(\n",
    "    cve_input: str,\n",
    "    top_k: int = 5,\n",
    "    run_llm: bool = False,\n",
    "    use_hyde: bool = False,\n",
    "    ollama_model: str = \"mistral:7b-instruct\",\n",
    "):\n",
    "    \"\"\"Hybrid CVE->CWE with optional HyDE (Phase 3):\n",
    "    - If CVE record has explicit CWE(s), show them.\n",
    "    - NEW: If use_hyde=True, generate hypothetical CWE definition before retrieval\n",
    "    - Always retrieve top-k candidates from CVE description (or HyDE document).\n",
    "    - Optionally run a local LLM reasoner (Ollama) on the retrieved candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    cve_id, data_or_err = read_cve_record(cve_input)\n",
    "    print(f\"### Hybrid results for {cve_id} ###\\n\")\n",
    "\n",
    "    if isinstance(data_or_err, str):\n",
    "        print(f\"Error: {data_or_err}\")\n",
    "        return\n",
    "\n",
    "    cve_data = data_or_err\n",
    "    desc = extract_cve_description(cve_data)\n",
    "\n",
    "    if desc:\n",
    "        print(\"CVE description:\")\n",
    "        print(desc)\n",
    "        print(\"\")\n",
    "\n",
    "    out = retrieve_cwes_for_cve(cve_data, top_k=top_k, use_hyde=use_hyde, ollama_model=ollama_model)\n",
    "\n",
    "    if out.get(\"hyde_document\"):\n",
    "        print(\"HyDE-generated CWE definition:\")\n",
    "        print(out[\"hyde_document\"])\n",
    "        print(\"\")\n",
    "\n",
    "    if out[\"explicit_cwes\"]:\n",
    "        print(\"Explicit CWEs in CVE record:\")\n",
    "        for cwe_id in out[\"explicit_cwes\"]:\n",
    "            pretty_print_cwe(cwe_id)\n",
    "        print(\"\")\n",
    "\n",
    "    if out[\"retrieved\"]:\n",
    "        print(f\"Retriever top-{top_k} CWE candidates (cosine similarity):\")\n",
    "        for c in out[\"retrieved\"]:\n",
    "            print(f\"- {c['cwe_id']} (score={c['score']:.4f}) — {c.get('name','')}\")\n",
    "        print(\"\")\n",
    "\n",
    "        prompt = build_reasoner_prompt(desc, out[\"retrieved\"], top_k=top_k)\n",
    "\n",
    "        if run_llm:\n",
    "            resp = run_ollama_reasoner(prompt, model=ollama_model)\n",
    "            if resp is None:\n",
    "                print(\"LLM reasoner not available (ollama missing or failed). Showing prompt instead:\\n\")\n",
    "                print(prompt)\n",
    "            else:\n",
    "                print(\"LLM reasoner output:\\n\")\n",
    "                print(resp)\n",
    "        else:\n",
    "            print(\"Reasoner prompt (copy/paste into your local LLM):\\n\")\n",
    "            print(prompt)\n",
    "    else:\n",
    "        print(\"No candidates retrieved (missing description or empty query).\")\n",
    "\n",
    "\n",
    "# Example usage (link or raw CVE ID both work)\n",
    "# If you installed Ollama + mistral:7b-instruct, set run_llm=True.\n",
    "# NEW: Set use_hyde=True to enable Phase 3 HyDE (Hypothetical Document Embeddings)\n",
    "lookup_cve_hybrid(\n",
    "    \"https://www.cve.org/CVERecord?id=CVE-2024-0001\",\n",
    "    top_k=5,\n",
    "    run_llm=True,\n",
    "    use_hyde=True,  # NEW: Enable HyDE\n",
    "    ollama_model=\"mistral:7b-instruct\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fortiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
